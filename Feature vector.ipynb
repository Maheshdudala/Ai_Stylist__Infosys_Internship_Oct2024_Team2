{"cells":[{"cell_type":"code","source":["pip install tensorflow opencv-python-headless numpy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23dn7qFnBdOw","executionInfo":{"status":"ok","timestamp":1731341992364,"user_tz":-330,"elapsed":4344,"user":{"displayName":"Akshara K","userId":"18379555469296361804"}},"outputId":"b388aee6-32b7-4c63-cc7f-df407f88a5f8"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import cv2  # OpenCV for image processing\n","from tensorflow.keras.applications import VGG16  # Pre-trained model\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.models import Model\n","\n"],"metadata":{"id":"SovDKEIWBi4n","executionInfo":{"status":"ok","timestamp":1731342163306,"user_tz":-330,"elapsed":426,"user":{"displayName":"Akshara K","userId":"18379555469296361804"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Load the VGG16 model with pre-trained ImageNet weights, excluding the top classification layer\n","base_model = VGG16(weights=\"imagenet\", include_top=False)\n","# Define a new model that outputs the feature maps instead of classification predictions\n","model = Model(inputs=base_model.input, outputs=base_model.output)"],"metadata":{"id":"BKSA9Qk7Blgv","executionInfo":{"status":"ok","timestamp":1731342481579,"user_tz":-330,"elapsed":830,"user":{"displayName":"Akshara K","userId":"18379555469296361804"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def extract_features(image_path):\n","    # Step 4a: Load the image\n","    image = cv2.imread(image_path)  # Read the image from the given path\n","    if image is None:\n","        print(\"Error: Unable to load image. Check the path.\")\n","        return None\n","\n","    # Step 4b: Resize the image to 224x224 pixels, as required by VGG16\n","    image = cv2.resize(image, (224, 224))\n","\n","    # Step 4c: Convert the image to an array and expand dimensions for batch compatibility\n","    image = img_to_array(image)\n","    image = np.expand_dims(image, axis=0)\n","\n","    # Step 4d: Preprocess the image for VGG16 (scales pixel values appropriately)\n","    image = preprocess_input(image)\n","\n","    # Step 4e: Use the model to predict and extract features\n","    features = model.predict(image)\n","\n","    # Step 4f: Flatten the features to a 1D vector if needed\n","    features = features.flatten()\n","\n","    return features\n"],"metadata":{"id":"XUyD88m0CSRp","executionInfo":{"status":"ok","timestamp":1731342486437,"user_tz":-330,"elapsed":417,"user":{"displayName":"Akshara K","userId":"18379555469296361804"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Replace this path with the path to an image on your computer\n","image_path = \"/content/moon.jpeg\"\n","\n","# Extract features and print the results\n","features = extract_features(image_path)\n","\n","if features is not None:\n","    print(\"Extracted feature vector shape:\", features.shape)\n","    print(\"Feature vector:\", features)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93B-qMqjDdFc","executionInfo":{"status":"ok","timestamp":1731342637193,"user_tz":-330,"elapsed":1688,"user":{"displayName":"Akshara K","userId":"18379555469296361804"}},"outputId":"395832a9-b967-418a-f642-25a31d43cf7b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","Extracted feature vector shape: (25088,)\n","Feature vector: [0.        0.        0.        ... 0.        1.5465443 0.       ]\n"]}]},{"cell_type":"code","source":["# Replace this path with the path to an image on your computer\n","image_path = \"/content/nature.jpeg\"\n","\n","# Extract features and print the results\n","features = extract_features(image_path)\n","\n","if features is not None:\n","    print(\"Extracted feature vector shape:\", features.shape)\n","    print(\"Feature vector:\", features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkWhzYcoECN3","executionInfo":{"status":"ok","timestamp":1731342666849,"user_tz":-330,"elapsed":861,"user":{"displayName":"Akshara K","userId":"18379555469296361804"}},"outputId":"81dbb4b2-62d2-43da-aa48-7d80ea252a50"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step\n","Extracted feature vector shape: (25088,)\n","Feature vector: [0. 0. 0. ... 0. 0. 0.]\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxa/uFSrtz7jv2kFQ6sdty"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}